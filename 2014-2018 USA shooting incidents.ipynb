{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"text-align: center;\">Shooting Incidents 2014 - 2018 dataset</p>\n",
    "\n",
    "The following files were obtined from the Gun Violence Archive (GVA) website, 5 datasets each providing information on incidents that have occured in a single year in the United States of America. The datasets are joined together to provide further insight on this epidemic, comparing rates and statistics between 45 states. (Datasets on GVA website do not include any information on the following 5 states: Hawaii, Idaho, New Hampshire, North Dakota & Wyoming)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'/Users/Nabzter/Documents/Masters/Data Programming/Coursework/assignment/2018.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8821138af664>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Concatenate 5 data framess collected from GVA site.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdf_18\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'/Users/Nabzter/Documents/Masters/Data Programming/Coursework/assignment/2018.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdf_17\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'/Users/Nabzter/Documents/Masters/Data Programming/Coursework/assignment/2017.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'/Users/Nabzter/Documents/Masters/Data Programming/Coursework/assignment/2018.csv' does not exist"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Concatenate 5 data framess collected from GVA site.\n",
    "df_18 = pd.read_csv(r'/Users/Nabzter/Documents/Masters/Data Programming/Coursework/assignment/2018.csv')\n",
    "\n",
    "df_17 = pd.read_csv(r'/Users/Nabzter/Documents/Masters/Data Programming/Coursework/assignment/2017.csv')\n",
    "\n",
    "df_16 = pd.read_csv(r'/Users/Nabzter/Documents/Masters/Data Programming/Coursework/assignment/2016.csv')\n",
    "\n",
    "df_15 = pd.read_csv(r'/Users/Nabzter/Documents/Masters/Data Programming/Coursework/assignment/2015.csv')\n",
    "\n",
    "df_14 = pd.read_csv(r'/Users/Nabzter/Documents/Masters/Data Programming/Coursework/assignment/2014.csv')\n",
    "\n",
    "#Drop Operations Column as it is not needed.\n",
    "\n",
    "data = [df_18, df_17, df_16, df_15, df_14]\n",
    "df = pd.concat(data)\n",
    "df = df.drop(['Operations'], axis = 1)\n",
    "\n",
    "# Convert string to datetime:\n",
    "\n",
    "df['Incident Date'] = pd.to_datetime(df['Incident Date'])\n",
    "\n",
    "# Create two new columns from newly converted datetime column this will assist with providing useful data. \n",
    "df['Month'] = pd.to_datetime(df['Incident Date']).dt.strftime('%m')\n",
    "df['Year'] = pd.to_datetime(df['Incident Date']).dt.strftime('%y')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General stats from shooting dataset (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total incidents (All killed and injured within 5 years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum of all kills and injuries located in given dataset. t_inc\n",
    "t_inc = df['# Killed'].sum() + df['# Injured'].sum()\n",
    "t_inc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total Killed (within 5 years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum of all killed in shooting incidents 2014 - 2018.\n",
    "\n",
    "t_kill = df['# Killed'].sum()\n",
    "t_kill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total Injured (within 5 years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum of all injured in shooting incidents 2014 - 2018.\n",
    "'''Injuries could vary from minor wounds to amputation. Unfortunately the extracted dataset does not provide\n",
    "this information. For this case study, I am solely looking at all those that are affected, whether injured or killed,\n",
    "from shooting incidents.'''\n",
    "\n",
    "t_inj = df['# Injured'].sum()\n",
    "t_inj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of killed and injured each year (2014 - 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of killed and injured in each year, during the 5 year period. t_yr\n",
    "t_yr = df.groupby(['Year']).sum()\n",
    "t_yr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of killed and injured per month in last 5 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Total number of killed and injured in each month during the 5 year period 2014 - 2018.\n",
    "\n",
    "t_mth = df.groupby(['Month']).sum()\n",
    "t_mth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total number of states in dataset = 46\n",
    "\n",
    "Missing and incomplete data on Gun Violence Archive site: Hawaii, Idaho, New Hampshire, North Dakota and Wyoming.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show number of killed and injured per state (i.e. total affected): t_stt\n",
    "t_stt = df.groupby(['State']).sum()\n",
    "\n",
    "'''Count the number of states included in df. This shows what states are missing from the imported dataset!'''\n",
    "\n",
    "print ('\\nStates =',t_stt.count(axis= 0)[0])\n",
    "\n",
    "t_stt[\"Total\"] = t_stt[\"# Killed\"].add(t_stt[\"# Injured\"])\n",
    "t_stt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Top 5 incident prone states - these values can be seen in a bar chart presented below providing absolute values\n",
    "# for each category\n",
    "\n",
    "t_stt['Total'] = t_stt['Total'].astype(str).astype(int)\n",
    "# Ordering Total column in t_stt from largest to smallest. inc_stt\n",
    "inc_stt = t_stt['Total'].nlargest(46)\n",
    "# Top 5 states with highest amount of incidents occured in the 5 year period 2014 - 2018.\n",
    "inc_stt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most amount killed in single incident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''max_killed indicates the single most deadliest shooting incident in the shooting dataset (df).\n",
    "The address will then be used to pinpoint and plot the exact location of the incident.'''\n",
    "\n",
    "# Provides data on maximum number of killed in a single shooting incident.\n",
    "max_killed = df['# Killed'].max()\n",
    "# Provides us with all the details of the particular incident found in shooting dataset\n",
    "max_killed = df[df['# Killed'] == max_killed]\n",
    "max_killed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Least amount killed in single incident  (789 incidents where no one was killed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''min_killed shows incidents with least killed. In this case there are 789 incidents where no deaths occured.'''\n",
    "\n",
    "# Provides data on minimum number of killed in a single shooting incident.\n",
    "min_killed = df['# Killed'].min()\n",
    "# Provides us with all the details on the particular incident found in shooting dataset\n",
    "min_killed = df[df['# Killed'] == min_killed]\n",
    "min_killed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphs\n",
    "\n",
    "Graphs show absolute values on those killed <font color = orange>orange</font> and injured <font color = blue>blue</font>. The final graph titled *Total killed and injured per state 2014 - 2018 (agg. 5 yrs)* has a third <font color = green>green</font> bar that adds killed and injured to provide total amount of incidents that have occured in each state. These graphs are far from perfect, 5 states are missing from the data and are highly biased due to obtaining the data from a single source. However, it does show the reader some states are more 'incident-prone' than others. This could be due to a number of factors, some of which will be analysed in the following section 'Interactive Maps'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Graphs have been converted from stacked to regular bar charts for more visability. Values shown are absolute.'''\n",
    "\n",
    "# Total killed and injured per year graph: t_yr\n",
    "t_yr.plot.bar(figsize = (10,5))\n",
    "plt.title('Total killed and injured per year', size = 20)\n",
    "plt.xticks(rotation=0)\n",
    "plt.xlabel('Year', size = 15)\n",
    "plt.ylabel('Affected', size = 15)\n",
    "plt.tight_layout()\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total killed and injured per month graph: t_mth\n",
    "t_mth.plot.bar(figsize = (10,5))\n",
    "plt.title('Total killed and injured per month (agg. 5yrs)', size = 20)\n",
    "plt.xticks(rotation=0)\n",
    "plt.xlabel('Month', size = 15)\n",
    "plt.ylabel('Affected', size = 15)\n",
    "plt.tight_layout()\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t_stt.plot.bar(figsize = (15,7))\n",
    "plt.title('Total killed and injured per state 2014 - 2018 (agg. 5 yrs)', size = 22)\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('State', size = 16)\n",
    "plt.ylabel('Affected', size = 16)\n",
    "plt.tight_layout()\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Analysis\n",
    "\n",
    "From the graph above we can see that most incidents (incidents = killed + injured) occured in 2017 followed by 2016. 2018 is considerably lower but that could be due to multiple factors (i.e. gathering data prior to end of the year, missing data on particular shooting incidents, etc) - causing skewness and bias in the data provided.\n",
    "\n",
    "In the months bar chart we see that there are three months where incidents spiked across the country - June, July and October. The intent of this was to see if there was an outlier in any of the months, this could be used to hypothesize whether certain factors such as weather (June, July - hot holiday season that increases <font color=red> population </font> in certain incident prone states) correlate with the number of shooting incidents.\n",
    "\n",
    "The final bar chart has three bars - # Killed, # Injured and Total (# Killed + # Injured). The values are absolute and do not take any other factors into account. As seen above <font color = green>t_stt</font> 5 states stand out in the graph: California, Florida, Illinois, Nevada and Texas (deadliest 5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Maps\n",
    "\n",
    "Three types of maps/libraries that provide further insight on specific areas:\n",
    "\n",
    "1) Folium, is used to pinpoint the deadliest shooting incident that occured in the past 5 years\n",
    "\n",
    "2) Plotly, open source API libraries that provide easy configurations for visual data. It is used to provide an interactive map of the United States, visualising the population (2017 taken as case study) and shooting incidents in each state\n",
    "\n",
    "3) Geopandas, open source project working that extends work used by pandas to allow spatial operations on geometric types. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Folium\n",
    "\n",
    "Folium is a powerful data visualization library in Python that was built primarily to help people visualize geospatial data. With Folium, one can create a map of any location in the world if its latitude and longitude values are known. In this case I have used folium to map out the deadliest incident logged into the shooting dataset **df**\n",
    "***\n",
    "In order to center the map in a specific area I have conducted an online search on the address linked with the shooting - **3950 Las Vegas Blvd S**. The coordinates are 36.090754,-115.17667, however these coordinates result in the map centering at the Mandalay Bay. Upon further research, I have configured the coordinates to center Las Vegas village 36.0956098,-115.1716268 (view interactive map below). I wanted to focus on the area where the incident had occured and not on the shooter.\n",
    "***\n",
    "Two markers were created, one pointing readers to the affected area (Las Vegas village hosting the Route 91 festival) i.e. where casualties occured during the incident. The other points towards the gunman who resided in The Mandalay Bay Hotel across the street. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "# input location coordinates of deadliest incident in shooting df [max_killed]: 3950 Las Vegas Boulevard\n",
    "# The zip code alon\n",
    "map = folium.Map(location=[36.0956098,-115.1716268],\n",
    "                    zoom_start = 15)\n",
    "folium.Marker([36.0956098,-115.1716268],\n",
    "              popup='Deadliest Shooting Incident (01/10/2017): 59 Killed, 441 Injured',\n",
    "             ).add_to(map)\n",
    "folium.Marker([36.090754,-115.17667],\n",
    "              popup='Location of mass murderer (committed suicide)',\n",
    "              icon=folium.Icon(color='red')\n",
    "             ).add_to(map)\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotly\n",
    "\n",
    "Plotly is a data analysis and graphing tool, its API can be accessed by creating an account (see below). It makes it possible for the editor to modify the data by accessing their built model on plotly's site.\n",
    "\n",
    "Below I have imported plotly and created an account on their site. Readers must do the same in order to access the graphs (API key will be provided once account is created).\n",
    "*** \n",
    "pmap, Population map plotted from a dataset acquired from github *see below*\n",
    "\n",
    "The first choropleth map shows the population of each state in the year 2014. Other years were not taken into account due to the fact that population change increased simultaneously in all states (top 5 remained the same). Therefore we can use this dataset to visually correlate population of each state along with the number of incidents occured in them.\n",
    "\n",
    "pmap includes all 50 states (District of Columbia is included however it is not a state) as well as Puerto Rico therefore it had 52 indexes/rows. This needed to be cleaned in order to provide clean and clear data - linking state, postal code, population and Total incidents (i.e. t_stt['Total']. *Further information provided below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.plotly as py\n",
    "\n",
    "# Create an account with a username on plotly, please replace 'username' below\n",
    "# This will result in them providing you with an API key, please copy key and replace 'blank' below.\n",
    "plotly.tools.set_credentials_file(username='pian2111', api_key='UJmGddNV6VQJIlgvH8Wq')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive map using plotly - Population of each state (2014 only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Population of each state in the USA (pmap). The dataset is specific to year 2014, this is used as a case study. \n",
    "# The dataset was retrieved from https://github.com/nmouky/datasets/blob/master/2014_usa_states.csv\n",
    "pmap = pd.read_csv('/Users/Nabzter/Documents/Masters/Data Programming/Coursework/assignment/datasets-master/2014_usa_states.csv')\n",
    "# Change population column from object type to int\n",
    "pmap['Population'] = pmap['Population'].astype('int')\n",
    "pmap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index of t_stt in order to see if index col matches pmap\n",
    "t_stt.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Remove 5 states from pmap to match data from shootings database. Otherwise data portrayed will be incorrect. \n",
    "# (data cleaning)\n",
    "pmap = pmap.drop(pmap.index[[11,12,29,34,39,51]])\n",
    "pmap.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in pmap.columns:\n",
    "    pmap[col] = pmap[col].astype(str)\n",
    "\n",
    "# Colour scale - defines colours to be shown on plotly map\n",
    "scl = [[0.0, 'rgb(240,240,240)'], \n",
    "       [0.2, 'rgb(200,200,200)'], \n",
    "       [0.4, 'rgb(150,150,150)'],\n",
    "       [0.6, 'rgb(100,100,100)'],\n",
    "       [0.8, 'rgb(50,50,50)'],\n",
    "       [1.0, 'rgb(0,0,0)']]\n",
    "\n",
    "# Defining type, shape, location and other parameters to define the map data\n",
    "'''Plotly map will be focused on the USA, using different states as own locations. This is done by defining each\n",
    "state with a postal code *pmap['Postal']*. Each state will be filled with its corresponding population'''\n",
    "data = [ dict(\n",
    "    type='choropleth',\n",
    "        colorscale = scl,\n",
    "        autocolorscale = False,\n",
    "        locations = pmap['Postal'],\n",
    "        z = pmap['Population'].astype(float),\n",
    "        locationmode = 'USA-states',\n",
    "        marker = dict(\n",
    "            line = dict (\n",
    "                color = 'rgb(255,255,255)',\n",
    "                width = 2\n",
    "            ) ),\n",
    "        colorbar = dict(\n",
    "            title = \"Population\")\n",
    "        ) ]\n",
    "\n",
    "# Layout of the plotly map\n",
    "layout = dict(\n",
    "        title = '2014 US Population (per state)',\n",
    "        geo = dict(\n",
    "            scope='usa',\n",
    "            projection = dict(type='albers usa'),\n",
    "            showlakes = False,\n",
    "            lakecolor = 'rgb(255, 255, 255)'),\n",
    "             )\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "py.iplot(fig, filename='d3-cloropleth-map')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive map using Plotly - Total Incidents per state (2014 - 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Same as above, however the variable counted and tested is the total number of incidents in past 5 years. \n",
    "# t_stt['Total']\n",
    "\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].astype(str)\n",
    "\n",
    "scl = [[0.0, 'rgb(240,240,240)'], \n",
    "       [0.1, 'rgb(225,225,225)'], \n",
    "       [0.2, 'rgb(200,200,200)'],\n",
    "       [0.3, 'rgb(175,175,175)'],\n",
    "       [0.4, 'rgb(150,150,150)'],\n",
    "       [0.5, 'rgb(125,125,125)'],\n",
    "      [0.6, 'rgb(100,100,100)'],\n",
    "      [0.7, 'rgb(75,75,75)'],\n",
    "      [0.8, 'rgb(50,50,50)'],\n",
    "      [0.9, 'rgb(25,25,25)'],\n",
    "      [1.0, 'rgb(0,0,0)']]\n",
    "\n",
    "'''Use pmap['Postal'] so that plotly can correctly allocate numerical data (z) to each and every state.\n",
    "The numerical data populating this map is total number of incidents that have occured past 5 years (2014 - 2018)'''\n",
    "\n",
    "data = [ dict(\n",
    "    type='choropleth',\n",
    "        colorscale = scl,\n",
    "        autocolorscale = False,\n",
    "        locations = pmap['Postal'],\n",
    "    z = t_stt['Total'],\n",
    "        locationmode = 'USA-states',\n",
    "        marker = dict(\n",
    "            line = dict (\n",
    "                color = 'rgb(255,255,255)',\n",
    "                width = 2\n",
    "            ) ),\n",
    "        colorbar = dict(\n",
    "            title = 'Total Incidents')\n",
    "        ) ]\n",
    "\n",
    "layout = dict(\n",
    "        title = 'Total Incidents (2014 - 2018)',\n",
    "        geo = dict(\n",
    "            scope='usa',\n",
    "            projection=dict( type='albers usa' ),\n",
    "            showlakes = False,\n",
    "            lakecolor = 'rgb(255, 255, 255)'),\n",
    "             )\n",
    "    \n",
    "fig = dict( data=data, layout=layout )\n",
    "py.iplot( fig, filename='d4-cloropleth-map' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotly maps: analysis\n",
    "\n",
    "Both interactive maps provide visual representations on each states population and number of incidents.\n",
    "Taking a step further, we can see that the there are 5 states where highest amount of incidents occur (41% of all incidents in USA) all of which have the highest population density except for Nevada (approx 2.84 million population). This could be due to multiple factors (drugs intake, population age, policing, etc.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GDP per state using Geopandas\n",
    "\n",
    "Geopandas extends datatypes used by pandas to allow spatial operations on geometric types. A shapefile is used to formulate the map of the USA along with each state. The shapefile is then merged with a csv file containing data on gross domestic product per state (during year 2017). Only one year is taken into account as GDP has proportionately increased over the years https://www.census.gov/geo/maps-data/data/cbf/cbf_state.html. Used the 2017 column in gdp file as a variable to plot the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Visually improves figure size\n",
    "plt.rcParams['figure.figsize'] = (100,20)\n",
    "\n",
    "# US-states shapefile - obtained from United States Census Bureau Website\n",
    "# https://www.census.gov/geo/maps-data/data/cbf/cbf_state.html\n",
    "shapefile = gpd.read_file('/Users/Nabzter/Documents/Masters/Data Programming/Coursework/assignment/cb_2017_us_state_5m (1)/cb_2017_us_state_5m.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GDP per state file - obtained from the Bureau of Economic Analysis \n",
    "df = pd.read_csv('/Users/Nabzter/Documents/Masters/Data Programming/Coursework/assignment/gdp.csv', header=0)\n",
    "\n",
    "# join the geodataframe with the gdp dataframe\n",
    "merged = shapefile.set_index('NAME').join(df.set_index('GeoName'))\n",
    "\n",
    "# Drop all states and areas which have been removed from other dataframes (Data cleaning)\n",
    "merged = merged.drop(['Commonwealth of the Northern Mariana Islands','American Samoa','Hawaii',\n",
    "                      'Guam','United States Virgin Islands','Idaho','North Dakota','New Hampshire',\n",
    "                      'Puerto Rico', 'Wyoming'])\n",
    "merged.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all NaN values in merged dataframe (further data cleaning)\n",
    "merged = merged.fillna(0)\n",
    "# Comvert 2017 column type from float to int\n",
    "merged['2017'] = merged['2017'].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GDP per state - geopandas map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a variable that will call whatever column we want to visualise on the map - in this case GDP per state in 2017\n",
    "variable = '2017'\n",
    "\n",
    "# create figure and axes for Matplotlib\n",
    "fig, ax = plt.subplots(1, figsize=(100, 15))\n",
    "\n",
    "# Create title and center\n",
    "plt.figtext(.5,.9,'Gross Domestic Product per state (2017)', fontsize=100, ha='center')\n",
    "\n",
    "# (Orange: # Killed, Blue: # Injured. as seen in bar charts above)\n",
    "merged.plot(column = variable, cmap = 'Purples', linewidth = 1.5, ax=ax, edgecolor= '0.5')\n",
    "\n",
    "# Double click on plot to zoom \n",
    "'''Fun Fact: Purple is the colour chosen - its what you get when mixing blue and orange!'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color = red>Note</font> on interactive maps\n",
    "The reader will realise that some key states have no data. This is due to lack of data provided in initial GVA dataset where states such as Idaho and Wyoming are missing. All interactive maps, graphs and stats have been affected from bias and skeweness of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''pmap1 is the same as pmap. population dataset. However, the states have been shifted to index column. \n",
    "This will allow to correlate a state's population with the number of incidents occured as well as the states gdp'''\n",
    "pmap1 = pmap.set_index('State')\n",
    "pmap1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmap1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert pmap1['Population'] column from object to int in order to be able to correlate with other numerical data\n",
    "pmap1['Population'] = pmap1['Population'].astype(int)\n",
    "pmap1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation: Incidents (Killed + Injured) and GDP per state    **0.78**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Incident GDP - cig\n",
    "cig = t_stt['Total'].corr(merged['2017'])\n",
    "cig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual of correlation between factors\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "# Correlation between GDP and Incidents\n",
    "plt.scatter(merged['2017'], t_stt['Total'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation: Incidents (Killed + Injured) and Population per state    **0.83**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Correlation between incidents per state and population per state. Correlation Incident and Population - cip\n",
    "cip = t_stt['Total'].corr(pmap1['Population'])\n",
    "cip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between population per state and incidents\n",
    "plt.scatter(pmap1['Population'],t_stt['Total'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation: Population and GDP per state   **0.98**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crr2 = pmap1['Population'].corr(merged['2017'])\n",
    "crr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between population per state and GDP\n",
    "plt.scatter(pmap1['Population'], merged['2017'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "***\n",
    "This notebook has shown some data manipulation and cleaning that has provided the reader with some stats on the topic. Furthermore, the graphs have shown the severity of gun violence and has visually shown the volume of those killed and injured in each year (t_yr), month (t_mth) and state (t_stt, *timeframe: 2014 - 2018). The notebook then progresses into interactive maps and pinpoints the deadliest incident logged in the compiled Gun Violence Archive dataset. Folium was used for this. It then progessed into mapping other factors such as population per state as well as total incidents occured per state, in which plotly was used. Two interactive choropleth maps were created, providing visual geospatial information. Removal of key states and other data cleaning methods were necessary in order to provide accurate information on both maps. A third library that creates interactive maps is introduced to provide the reader with a variety of ways to see data, geopandas. The map was plotted by merging key elements in a shapefile and the GDP dataset. Finally to test relations between all three factors, a correlation function is adopted. Pearson's linear correlation shows the reader the differing levels of correlation between each factor. The correlation coefficient between shooting incidents in each state and GDP is 0.78, while the correlation coefficient between shooting incidents and total population per state is 0.83 (this could be due to having low GDP per capita and overall high GDP, i.e. imbalance of wealth in certain states). And finally, the correlation between total population and GDP per state is 0.98! \n",
    "*** \n",
    "To conclude, all three correlations are highly positive however correlation does not imply causation, thus this study is highly hypothetical. Furthermore, the lack of information on 5 key states along with niche datasets (i.e. GDP per state in 2017 and Population per state 2014) cause a lot of bias and skewness in the data. Other factors could be studied such as drug intake, policing, age demographics, etc. Nevertheless, this notebook has provided some interesting findings: more money, more people, more violence.\n",
    "\n",
    "*Note to self: Leave London and buy a house in Isle of Skye"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
